Prepare the Oxford-102 flowers dataset for reproducing main results in the paper,
@article{han2016stackgan,
  title={StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks},
  author={Han Zhang and Tao Xu and Hongsheng Li and Shaoting Zhang and Xiaolei Huang and Xiaogang Wang and Dimitris Metaxas},
  journal={arXiv:1612.03242},
  year={2016}
}


1. Save this preprocessed data to Data/.
The text description data and char-CNN-RNN text embeddings are downloaded from
https://github.com/reedscot/cvpr2016.
Also, we follow this paper to split the dataset into train and test subsets.
@inproceedings{reed2016learning,
 title = {Learning Deep Representations of Fine-Grained Visual Descriptions,
 booktitle = {IEEE Computer Vision and Pattern Recognition},
 year = {2016},
 author = {Scott Reed and Zeynep Akata and Bernt Schiele and Honglak Lee},
}


2 Download the image data from http://www.robots.ox.ac.uk/~vgg/data/flowers/102/;
Unzip it to Data/flowers/102flowers/ and run "python ./misc/preprocess_flowers.py".
@InProceedings{Nilsback08,
   author = "Nilsback, M-E. and Zisserman, A.",
   title = "Automated Flower Classification over a Large Number of Classes",
   booktitle = "Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing",
   year = "2008",
   month = "Dec"
}
